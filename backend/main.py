import torch

# Optimization for 8 CPU Cores on Railway
torch.set_num_threads(8)
torch.set_num_interop_threads(1)

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import os
import json
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# NER / NEL Integration
try:
    from backend.utils.ner import ClinicalNER
except ImportError:
    from utils.ner import ClinicalNER

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load data
# Load Master Dataset (SFDA + SDI Enriched)
csv_path = "data/master_drugs_data.csv.gz"
if not os.path.exists(csv_path):
    csv_path = "backend/data/master_drugs_data.csv.gz"

# Fallback to uncompressed if necessary
if not os.path.exists(csv_path):
    csv_path = "data/master_drugs_data.csv"
    if not os.path.exists(csv_path):
        csv_path = "backend/data/master_drugs_data.csv"

# Pandas auto-detects gzip
df = pd.read_csv(csv_path)

# Initialize NER Engine
ner_engine = ClinicalNER()

# Load Model
model_name = "Qwen/Qwen2.5-0.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

class Query(BaseModel):
    symptoms: str
    temperature: str
    history: str
    medications: str
    age_weight: str

@app.get("/debug/data")
async def debug_data():
    try:
        import os
        return {
            "cwd": os.getcwd(),
            "df_rows": len(df) if 'df' in globals() else "Not Defined",
            "map_size": len(ner_engine.symptoms_map) if 'ner_engine' in globals() else "Not Defined",
            "symptoms_file_exists": any([os.path.exists(p) for p in ["data/symptoms_mapping.json", "backend/data/symptoms_mapping.json"]]),
            "sample_map": list(ner_engine.symptoms_map.keys())[:3] if 'ner_engine' in globals() and ner_engine.symptoms_map else "Empty",
            "status": "Alive"
        }
    except Exception as e:
        return {"error": str(e), "type": str(type(e))}

@app.post("/consult")
async def consult(query: Query):
    # 1. NER & Entity Recognition Phase
    # Extract symptoms, standardized terms, and link international brands
    entities = ner_engine.extract_entities(query)
    
    search_terms = entities['search_terms']
    mapped_brands = entities['international_links']

    # 2. RAG Retrieval Phase
    relevant_drugs = []
    
    # Perform Search in Master DB
    for _, row in df.iterrows():
        trade = str(row["Trade Name"]).lower()
        scientific = str(row["Scientific Name"]).lower()
        
        # Check for matches
        matched = False
        for term in search_terms:
            t = term.lower()
            if t in trade or t in scientific:
                matched = True
                break
        
        if matched:
            relevant_drugs.append(row.to_dict())
        
        if len(relevant_drugs) >= 5: 
            break
            
    context = ""
    if relevant_drugs:
        context = "Relevant SFDA Drug Data & Clinical Instructions (Master Dataset):\n"
        for d in relevant_drugs:
            context += f"- {d['Trade Name']} ({d['Scientific Name']}): {d['Dosage Form']}, Strength: {d['Strength']}, Administration: {d['Administration Route (AR)'] if pd.notna(d['Administration Route (AR)']) else d['Administration Route']}\n"
            if pd.notna(d['Patient Leaflet (AR)']):
                context += f"  Official Instructions: {str(d['Patient Leaflet (AR)'])[:800]}...\n"
            if 'International Dosage' in d and pd.notna(d['International Dosage']) and d['International Dosage'] != "":
                context += f"  International Dosage Protocols (Drugs.com): {str(d['International Dosage'])[:800]}...\n"

    # Add International Bridge Note to Context
    if mapped_brands:
        context += "\n[System Note: International Brand Mapping (NER/NEL)]\n"
        for brand, ing in mapped_brands.items():
            context += f"- User mentioned '{brand}' (International). Mapped via NER to active ingredient '{ing}' to find local equivalent.\n"

    if not context:
        context = "No specific match found in SFDA master database for translated keywords."

    # 3. Formulate prompt to generate response in ARABIC
    system_prompt = f"""Ø§Ù„ØµÙŠØ¯Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø§Ù„Ø°ÙƒÙŠ:
Ø§Ø³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„ØºØ°Ø§Ø¡ ÙˆØ§Ù„Ø¯ÙˆØ§Ø¡ (SFDA) Ù„ØªÙ‚Ø¯ÙŠÙ… Ù†ØµÙŠØ­Ø© Ø·Ø¨ÙŠØ© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ ÙÙ‚Ø·.
ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø­ØµØ±Ø§Ù‹ ÙˆØ¨ØµÙŠØºØ© Ù…Ù‡Ù†ÙŠØ©.

Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø±Ø¯Ùƒ:
ğŸ’Š Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡:
ğŸ“ Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© (Ù„Ù€ {query.age_weight}):
    *Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ ØªÙˆÙØ±Øª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† "International Dosage"ØŒ ÙŠØ±Ø¬Ù‰ Ø°ÙƒØ± Ø§Ù„ØªÙØ§ØµÙŠÙ„ (Ù„Ù„Ø¨Ø§Ù„ØºÙŠÙ†/Ø§Ù„Ø£Ø·ÙØ§Ù„) Ø¨Ø¯Ù‚Ø©.*
âš ï¸ ØªØ­Ø°ÙŠØ±Ø§Øª Ù‡Ø§Ù…Ø©:

Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‡ÙŠØ¦Ø© (Context):
{context}

Ù†ØµÙŠØ­Ø© Ø§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø±Ø³Ù…ÙŠØ©:
âœ… Ø­Ø§Ù„Ø© Ø§Ù„Ù‡ÙŠØ¦Ø©: ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù‡ÙŠØ¦Ø© Ø§Ù„ØºØ°Ø§Ø¡ ÙˆØ§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø±Ø³Ù…ÙŠØ©."""
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶: {query.symptoms}. Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø·Ø¨ÙŠ: {query.history}. Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {query.medications}. Ù…Ø§ Ù‡ÙŠ Ù†ØµÙŠØ­ØªÙƒØŸ"}
    ]
    
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

    generated_ids = model.generate(
        **model_inputs,
        max_new_tokens=512
    )
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]

    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return {"message": response}

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)
