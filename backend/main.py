import torch

# Optimization for 8 CPU Cores on Railway
torch.set_num_threads(8)
torch.set_num_interop_threads(1)

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import pandas as pd
import os
import json
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# NER / NEL Integration
try:
    from backend.utils.ner import ClinicalNER
except ImportError:
    from utils.ner import ClinicalNER

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load data
# Load Master Dataset (SFDA + SDI Enriched)
csv_path = "data/master_drugs_data.csv.gz"
if not os.path.exists(csv_path):
    csv_path = "backend/data/master_drugs_data.csv.gz"

# Fallback to uncompressed if necessary
if not os.path.exists(csv_path):
    csv_path = "data/master_drugs_data.csv"
    if not os.path.exists(csv_path):
        csv_path = "backend/data/master_drugs_data.csv"

# Pandas auto-detects gzip
df = pd.read_csv(csv_path)

# Initialize NER Engine
ner_engine = ClinicalNER()

# Load Model
model_name = "Qwen/Qwen2.5-1.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

class Query(BaseModel):
    symptoms: str
    temperature: str
    history: str
    medications: str
    age_weight: str

@app.get("/debug/data")
async def debug_data():
    try:
        import os
        return {
            "cwd": os.getcwd(),
            "df_rows": len(df) if 'df' in globals() else "Not Defined",
            "map_size": len(ner_engine.symptoms_map) if 'ner_engine' in globals() else "Not Defined",
            "symptoms_file_exists": any([os.path.exists(p) for p in ["data/symptoms_mapping.json", "backend/data/symptoms_mapping.json"]]),
            "sample_map": list(ner_engine.symptoms_map.keys())[:3] if 'ner_engine' in globals() and ner_engine.symptoms_map else "Empty",
            "status": "Alive"
        }
    except Exception as e:
        return {"error": str(e), "type": str(type(e))}

@app.post("/consult")
async def consult(query: Query):
    # 1. NER & Entity Recognition Phase
    # Extract symptoms, standardized terms, and link international brands
    entities = ner_engine.extract_entities(query)
    
    search_terms = entities['search_terms']
    mapped_brands = entities['international_links']

    # 2. RAG Retrieval Phase
    relevant_drugs = []
    
    # Perform Search in Master DB
    import re
    for _, row in df.iterrows():
        trade = str(row["Trade Name"]).lower()
        scientific = str(row["Scientific Name"]).lower()
        
        # Check for matches (Regex Word Boundary)
        matched = False
        for term in search_terms:
            # Escape to handle special chars like '+' in 'Cold + Flu'
            # \b matches word boundary
            pattern = r'\b' + re.escape(term.lower()) + r'\b'
            if re.search(pattern, trade) or re.search(pattern, scientific):
                matched = True
                break
        
        if matched:
            relevant_drugs.append(row.to_dict())
        
        if len(relevant_drugs) >= 4: 
            break
            
    context = ""
    if relevant_drugs:
        context = "Relevant SFDA Drug Data & Clinical Instructions (Master Dataset):\n"
        for d in relevant_drugs:
            context += f"- {d['Trade Name']} ({d['Scientific Name']}): {d['Dosage Form']}, Strength: {d['Strength']}, Price: {d['Price (SAR)']} SAR, Administration: {d['Administration Route (AR)'] if pd.notna(d['Administration Route (AR)']) else d['Administration Route']}\n"
            if pd.notna(d['Patient Leaflet (AR)']):
                context += f"  Official Instructions: {str(d['Patient Leaflet (AR)'])[:800]}...\n"
            if 'International Dosage' in d and pd.notna(d['International Dosage']) and d['International Dosage'] != "":
                context += f"  International Dosage Protocols (Drugs.com): {str(d['International Dosage'])[:800]}...\n"

    # Add International Bridge Note to Context
    if mapped_brands:
        context += "\n[System Note: International Brand Mapping (NER/NEL)]\n"
        for brand, ing in mapped_brands.items():
            context += f"- User mentioned '{brand}' (International). Mapped via NER to active ingredient '{ing}' to find local equivalent.\n"

    if not context:
        context = "No specific match found in SFDA master database for translated keywords."

    # 3. Formulate prompt to generate response in ARABIC
    education_rule = ""
    # Simple heuristic: if "Ø³Ù†Ø©" in age_weight and number < 12 => force liquids?
    # Actually, let the LLM deduce from "{query.age_weight}".
    
    system_prompt = f"""Ø£Ù†Øª ØµÙŠØ¯Ù„ÙŠ Ø³Ø¹ÙˆØ¯ÙŠ Ø®Ø¨ÙŠØ±.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„ØªÙ‚Ø¯ÙŠÙ… Ù†ØµÙŠØ­Ø© Ø¹Ù„Ø§Ø¬ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©.
Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¯ÙˆÙŠØ© Ù…Ø¹ Ø£Ø³Ø¹Ø§Ø±Ù‡Ø§.
Ø§Ø®ØªØ± Ø£ÙØ¶Ù„ 1-3 Ø£Ø¯ÙˆÙŠØ© (Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 4).

ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù‡Ø§Ù…Ø© Ø¬Ø¯Ø§Ù‹ (Critical Instructions):
1. **Ø¹Ø¯Ù… Ø§Ù„ØªÙƒØ±Ø§Ø±**: Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª Ù†ÙØ³ Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø¨Ø£Ø´ÙƒØ§Ù„ Ù…Ø®ØªÙ„ÙØ©ØŒ Ø§Ø®ØªØ± Ø§Ù„Ø£Ù†Ø³Ø¨ Ù„Ù„Ø¹Ù…Ø±.
2. **Ø£Ø·ÙØ§Ù„ Ø£Ù‚Ù„ Ù…Ù† 12 Ø³Ù†Ø©**: âš ï¸ ÙŠÙ…Ù†Ø¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø§Ù‚ØªØ±Ø§Ø­ Ø§Ù„Ø­Ø¨ÙˆØ¨ Ø£Ùˆ Ø§Ù„ÙƒØ¨Ø³ÙˆÙ„Ø§Øª. ÙŠØ¬Ø¨ Ø§Ù‚ØªØ±Ø§Ø­ (Syrup, Suspension, Solution, Drops) ÙÙ‚Ø·.
3. **Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø£Ø³Ù…Ø§Ø¡ ÙÙ‚Ø·**: Ø§ÙƒØªØ¨ Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ ÙÙ‚Ø· ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø§Øª.
4. **Ø§Ù„Ø£Ø³Ø¹Ø§Ø±**: Ø¶Ø¹ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø­ØµØ±Ø§Ù‹ ÙÙŠ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©.

Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªÙ…Ø§Ù…Ø§Ù‹:

1. ğŸ’Š Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:
   - [Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ 1]
   - [Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ 2]

2. ğŸ¤” Ù„Ù…Ø§Ø°Ø§ Ù†Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙˆØ§Ø¡ØŸ:
   - [Ø§Ø³Ù… Ø¯ÙˆØ§Ø¡ 1]: [Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· Ù„Ø¯ÙˆØ§Ø¹ÙŠ Ø§Ù„Ø§Ø³ØªØ¹Ù…Ø§Ù„]
   - [Ø§Ø³Ù… Ø¯ÙˆØ§Ø¡ 2]: [Ø§Ù„Ø´Ø±Ø­]

3. âœ… Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ§Ù„Ø¬Ø±Ø¹Ø© (Ù„Ù€ {query.age_weight}):
   - [Ø§Ø³Ù… Ø¯ÙˆØ§Ø¡ 1]: [Ø§Ù„Ø¬Ø±Ø¹Ø©] - [Ø§Ù„Ø¹Ø¯Ø¯ ÙŠÙˆÙ…ÙŠØ§Ù‹] - [Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯ Ø§Ù„Ø£ÙƒÙ„]
   - [Ø§Ø³Ù… Ø¯ÙˆØ§Ø¡ 2]: [Ø§Ù„ØªÙØ§ØµÙŠÙ„]

4. ğŸ’° Ø§Ù„Ø£Ø³Ø¹Ø§Ø± (Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©):
   - [Ø§Ø³Ù… Ø¯ÙˆØ§Ø¡ 1]: [Ø§Ù„Ø³Ø¹Ø±] Ø±ÙŠØ§Ù„ Ø³Ø¹ÙˆØ¯ÙŠ
   - [Ø§Ø³Ù… Ø¯ÙˆØ§Ø¡ 2]: [Ø§Ù„Ø³Ø¹Ø±] Ø±ÙŠØ§Ù„ Ø³Ø¹ÙˆØ¯ÙŠ

âš ï¸ ØªØ­Ø°ÙŠØ±Ø§Øª Ù‡Ø§Ù…Ø©: [ØªØ­Ø°ÙŠØ±Ø§Øª Ø¹Ø§Ù…Ø© Ø£Ùˆ Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©]

Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‡ÙŠØ¦Ø© (Context):
{context}

Ù†ØµÙŠØ­Ø© Ø§Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø±Ø³Ù…ÙŠØ©:
âœ… Ø­Ø§Ù„Ø© Ø§Ù„Ù‡ÙŠØ¦Ø©: ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù‡ÙŠØ¦Ø© Ø§Ù„ØºØ°Ø§Ø¡ ÙˆØ§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø±Ø³Ù…ÙŠØ©."""
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶: {query.symptoms}. Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø·Ø¨ÙŠ: {query.history}. Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {query.medications}. Ù…Ø§ Ù‡ÙŠ Ù†ØµÙŠØ­ØªÙƒØŸ"}
    ]
    
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

    generated_ids = model.generate(
        **model_inputs,
        max_new_tokens=512
    )
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]

    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return {"message": response}

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)
